{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75faed78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nnfs\n",
      "  Downloading nnfs-0.5.1-py3-none-any.whl (9.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nnfs) (1.21.6)\n",
      "Installing collected packages: nnfs\n",
      "Successfully installed nnfs-0.5.1\n"
     ]
    }
   ],
   "source": [
    "! pip install nnfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12b101ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "\n",
    "nnfs.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bcd1542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense layer\n",
    "class Layer_Dense:\n",
    "\n",
    "    # Layer initialization\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        # Initialize weights and biases\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "        # Calculate output values from inputs, weights and biases\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Gradients on parameters\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
    "        # Gradient on values\n",
    "        self.dinputs = np.dot(dvalues, self.weights.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f3097d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU activation\n",
    "class Activation_ReLU:\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "        # Calculate output values from inputs\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Since we need to modify original variable,\n",
    "        # let's make a copy of values first\n",
    "        self.dinputs = dvalues.copy()\n",
    "\n",
    "        # Zero gradient where input values were negative\n",
    "        self.dinputs[self.inputs <= 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4194f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax activation\n",
    "class Activation_Softmax:\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "\n",
    "        # Get unnormalized probabilities\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1,\n",
    "                                            keepdims=True))\n",
    "        # Normalize them for each sample\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1,\n",
    "                                            keepdims=True)\n",
    "\n",
    "        self.output = probabilities\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "\n",
    "        # Create uninitialized array\n",
    "        self.dinputs = np.empty_like(dvalues)\n",
    "\n",
    "        # Enumerate outputs and gradients\n",
    "        for index, (single_output, single_dvalues) in \\\n",
    "                enumerate(zip(self.output, dvalues)):\n",
    "            # Flatten output array\n",
    "            single_output = single_output.reshape(-1, 1)\n",
    "            # Calculate Jacobian matrix of the output\n",
    "            jacobian_matrix = np.diagflat(single_output) - \\\n",
    "                              np.dot(single_output, single_output.T)\n",
    "            # Calculate sample-wise gradient\n",
    "            # and add it to the array of sample gradients\n",
    "            self.dinputs[index] = np.dot(jacobian_matrix,\n",
    "                                         single_dvalues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e1c2068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD optimizer\n",
    "class Optimizer_SGD:\n",
    "\n",
    "    # Initialize optimizer - set settings,\n",
    "    # learning rate of 1. is default for this optimizer\n",
    "    def __init__(self, learning_rate=1., decay=0., momentum=0.):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.momentum = momentum\n",
    "\n",
    "    # Call once before any parameter updates\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * \\\n",
    "                (1. / (1. + self.decay * self.iterations))\n",
    "\n",
    "    # Update parameters\n",
    "    def update_params(self, layer):\n",
    "\n",
    "        # If we use momentum\n",
    "        if self.momentum:\n",
    "\n",
    "            # If layer does not contain momentum arrays, create them\n",
    "            # filled with zeros\n",
    "            if not hasattr(layer, 'weight_momentums'):\n",
    "                layer.weight_momentums = np.zeros_like(layer.weights)\n",
    "                # If there is no momentum array for weights\n",
    "                # The array doesn't exist for biases yet either.\n",
    "                layer.bias_momentums = np.zeros_like(layer.biases)\n",
    "\n",
    "            # Build weight updates with momentum - take previous\n",
    "            # updates multiplied by retain factor and update with\n",
    "            # current gradients\n",
    "            weight_updates = \\\n",
    "                self.momentum * layer.weight_momentums - \\\n",
    "                self.current_learning_rate * layer.dweights\n",
    "            layer.weight_momentums = weight_updates\n",
    "\n",
    "            # Build bias updates\n",
    "            bias_updates = \\\n",
    "                self.momentum * layer.bias_momentums - \\\n",
    "                self.current_learning_rate * layer.dbiases\n",
    "            layer.bias_momentums = bias_updates\n",
    "\n",
    "        # Vanilla SGD updates (as before momentum update)\n",
    "        else:\n",
    "            weight_updates = -self.current_learning_rate * \\\n",
    "                             layer.dweights\n",
    "            bias_updates = -self.current_learning_rate * \\\n",
    "                           layer.dbiases\n",
    "\n",
    "        # Update weights and biases using either\n",
    "        # vanilla or momentum updates\n",
    "        layer.weights += weight_updates\n",
    "        layer.biases += bias_updates\n",
    "\n",
    "\n",
    "    # Call once after any parameter updates\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e04d1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common loss class\n",
    "class Loss:\n",
    "\n",
    "    # Calculates the data and regularization losses\n",
    "    # given model output and ground truth values\n",
    "    def calculate(self, output, y):\n",
    "\n",
    "        # Calculate sample losses\n",
    "        sample_losses = self.forward(output, y)\n",
    "\n",
    "        # Calculate mean loss\n",
    "        data_loss = np.mean(sample_losses)\n",
    "\n",
    "        # Return loss\n",
    "        return data_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "473da508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-entropy loss\n",
    "class Loss_CategoricalCrossentropy(Loss):\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, y_pred, y_true):\n",
    "\n",
    "        # Number of samples in a batch\n",
    "        samples = len(y_pred)\n",
    "        # Clip data to prevent division by 0\n",
    "        # Clip both sides to not drag mean towards any value\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "\n",
    "        # Probabilities for target values -\n",
    "        # only if categorical labels\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[\n",
    "                range(samples),\n",
    "                y_true\n",
    "            ]\n",
    "\n",
    "        # Mask values - only for one-hot encoded labels\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(\n",
    "                y_pred_clipped * y_true,\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "        # Losses\n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "        return negative_log_likelihoods\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "        # Number of labels in every sample\n",
    "        # We'll use the first sample to count them\n",
    "        labels = len(dvalues[0])\n",
    "\n",
    "        # If labels are sparse, turn them into one-hot vector\n",
    "        if len(y_true.shape) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "\n",
    "        # Calculate gradient\n",
    "        self.dinputs = -y_true / dvalues\n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8db3a1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax classifier - combined Softmax activation\n",
    "# and cross-entropy loss for faster backward step\n",
    "class Activation_Softmax_Loss_CategoricalCrossentropy():\n",
    "\n",
    "    # Creates activation and loss function objects\n",
    "    def __init__(self):\n",
    "        self.activation = Activation_Softmax()\n",
    "        self.loss = Loss_CategoricalCrossentropy()\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs, y_true):\n",
    "        # Output layer's activation function\n",
    "        self.activation.forward(inputs)\n",
    "        # Set the output\n",
    "        self.output = self.activation.output\n",
    "        # Calculate and return loss value\n",
    "        return self.loss.calculate(self.output, y_true)\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "\n",
    "        # If labels are one-hot encoded,\n",
    "        # turn them into discrete values\n",
    "        if len(y_true.shape) == 2:\n",
    "            y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "        # Copy so we can safely modify\n",
    "        self.dinputs = dvalues.copy()\n",
    "        # Calculate gradient\n",
    "        self.dinputs[range(samples), y_true] -= 1\n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26e62424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.360, loss: 1.099, lr: 1.0\n",
      "epoch: 100, acc: 0.400, loss: 1.087, lr: 1.0\n",
      "epoch: 200, acc: 0.417, loss: 1.077, lr: 1.0\n",
      "epoch: 300, acc: 0.420, loss: 1.076, lr: 1.0\n",
      "epoch: 400, acc: 0.400, loss: 1.074, lr: 1.0\n",
      "epoch: 500, acc: 0.400, loss: 1.071, lr: 1.0\n",
      "epoch: 600, acc: 0.417, loss: 1.067, lr: 1.0\n",
      "epoch: 700, acc: 0.437, loss: 1.062, lr: 1.0\n",
      "epoch: 800, acc: 0.430, loss: 1.055, lr: 1.0\n",
      "epoch: 900, acc: 0.390, loss: 1.064, lr: 1.0\n",
      "epoch: 1000, acc: 0.400, loss: 1.062, lr: 1.0\n",
      "epoch: 1100, acc: 0.443, loss: 1.061, lr: 1.0\n",
      "epoch: 1200, acc: 0.403, loss: 1.061, lr: 1.0\n",
      "epoch: 1300, acc: 0.387, loss: 1.052, lr: 1.0\n",
      "epoch: 1400, acc: 0.387, loss: 1.106, lr: 1.0\n",
      "epoch: 1500, acc: 0.430, loss: 1.043, lr: 1.0\n",
      "epoch: 1600, acc: 0.410, loss: 1.063, lr: 1.0\n",
      "epoch: 1700, acc: 0.397, loss: 1.043, lr: 1.0\n",
      "epoch: 1800, acc: 0.450, loss: 1.038, lr: 1.0\n",
      "epoch: 1900, acc: 0.483, loss: 1.025, lr: 1.0\n",
      "epoch: 2000, acc: 0.403, loss: 1.037, lr: 1.0\n",
      "epoch: 2100, acc: 0.457, loss: 1.022, lr: 1.0\n",
      "epoch: 2200, acc: 0.493, loss: 1.020, lr: 1.0\n",
      "epoch: 2300, acc: 0.443, loss: 1.002, lr: 1.0\n",
      "epoch: 2400, acc: 0.480, loss: 0.994, lr: 1.0\n",
      "epoch: 2500, acc: 0.490, loss: 1.009, lr: 1.0\n",
      "epoch: 2600, acc: 0.480, loss: 0.991, lr: 1.0\n",
      "epoch: 2700, acc: 0.540, loss: 0.972, lr: 1.0\n",
      "epoch: 2800, acc: 0.473, loss: 0.998, lr: 1.0\n",
      "epoch: 2900, acc: 0.527, loss: 0.963, lr: 1.0\n",
      "epoch: 3000, acc: 0.543, loss: 0.985, lr: 1.0\n",
      "epoch: 3100, acc: 0.523, loss: 0.988, lr: 1.0\n",
      "epoch: 3200, acc: 0.487, loss: 0.976, lr: 1.0\n",
      "epoch: 3300, acc: 0.493, loss: 0.973, lr: 1.0\n",
      "epoch: 3400, acc: 0.477, loss: 0.984, lr: 1.0\n",
      "epoch: 3500, acc: 0.520, loss: 0.993, lr: 1.0\n",
      "epoch: 3600, acc: 0.537, loss: 0.965, lr: 1.0\n",
      "epoch: 3700, acc: 0.550, loss: 0.997, lr: 1.0\n",
      "epoch: 3800, acc: 0.483, loss: 0.963, lr: 1.0\n",
      "epoch: 3900, acc: 0.493, loss: 0.970, lr: 1.0\n",
      "epoch: 4000, acc: 0.520, loss: 0.971, lr: 1.0\n",
      "epoch: 4100, acc: 0.540, loss: 0.989, lr: 1.0\n",
      "epoch: 4200, acc: 0.547, loss: 0.956, lr: 1.0\n",
      "epoch: 4300, acc: 0.573, loss: 0.995, lr: 1.0\n",
      "epoch: 4400, acc: 0.483, loss: 0.959, lr: 1.0\n",
      "epoch: 4500, acc: 0.493, loss: 0.969, lr: 1.0\n",
      "epoch: 4600, acc: 0.520, loss: 0.974, lr: 1.0\n",
      "epoch: 4700, acc: 0.543, loss: 0.987, lr: 1.0\n",
      "epoch: 4800, acc: 0.547, loss: 0.962, lr: 1.0\n",
      "epoch: 4900, acc: 0.553, loss: 1.007, lr: 1.0\n",
      "epoch: 5000, acc: 0.510, loss: 0.973, lr: 1.0\n",
      "epoch: 5100, acc: 0.530, loss: 0.966, lr: 1.0\n",
      "epoch: 5200, acc: 0.547, loss: 0.986, lr: 1.0\n",
      "epoch: 5300, acc: 0.550, loss: 0.961, lr: 1.0\n",
      "epoch: 5400, acc: 0.557, loss: 1.001, lr: 1.0\n",
      "epoch: 5500, acc: 0.520, loss: 0.966, lr: 1.0\n",
      "epoch: 5600, acc: 0.513, loss: 0.956, lr: 1.0\n",
      "epoch: 5700, acc: 0.570, loss: 0.975, lr: 1.0\n",
      "epoch: 5800, acc: 0.553, loss: 0.936, lr: 1.0\n",
      "epoch: 5900, acc: 0.577, loss: 0.972, lr: 1.0\n",
      "epoch: 6000, acc: 0.490, loss: 0.940, lr: 1.0\n",
      "epoch: 6100, acc: 0.557, loss: 0.951, lr: 1.0\n",
      "epoch: 6200, acc: 0.533, loss: 0.937, lr: 1.0\n",
      "epoch: 6300, acc: 0.590, loss: 0.956, lr: 1.0\n",
      "epoch: 6400, acc: 0.563, loss: 0.929, lr: 1.0\n",
      "epoch: 6500, acc: 0.593, loss: 0.955, lr: 1.0\n",
      "epoch: 6600, acc: 0.523, loss: 0.919, lr: 1.0\n",
      "epoch: 6700, acc: 0.567, loss: 0.928, lr: 1.0\n",
      "epoch: 6800, acc: 0.560, loss: 0.890, lr: 1.0\n",
      "epoch: 6900, acc: 0.587, loss: 0.871, lr: 1.0\n",
      "epoch: 7000, acc: 0.593, loss: 0.905, lr: 1.0\n",
      "epoch: 7100, acc: 0.623, loss: 0.860, lr: 1.0\n",
      "epoch: 7200, acc: 0.583, loss: 0.868, lr: 1.0\n",
      "epoch: 7300, acc: 0.600, loss: 0.874, lr: 1.0\n",
      "epoch: 7400, acc: 0.597, loss: 0.849, lr: 1.0\n",
      "epoch: 7500, acc: 0.607, loss: 0.914, lr: 1.0\n",
      "epoch: 7600, acc: 0.657, loss: 0.858, lr: 1.0\n",
      "epoch: 7700, acc: 0.620, loss: 0.853, lr: 1.0\n",
      "epoch: 7800, acc: 0.630, loss: 0.862, lr: 1.0\n",
      "epoch: 7900, acc: 0.580, loss: 0.878, lr: 1.0\n",
      "epoch: 8000, acc: 0.617, loss: 0.874, lr: 1.0\n",
      "epoch: 8100, acc: 0.597, loss: 0.839, lr: 1.0\n",
      "epoch: 8200, acc: 0.593, loss: 0.852, lr: 1.0\n",
      "epoch: 8300, acc: 0.580, loss: 0.923, lr: 1.0\n",
      "epoch: 8400, acc: 0.647, loss: 0.879, lr: 1.0\n",
      "epoch: 8500, acc: 0.630, loss: 0.838, lr: 1.0\n",
      "epoch: 8600, acc: 0.630, loss: 0.853, lr: 1.0\n",
      "epoch: 8700, acc: 0.627, loss: 0.863, lr: 1.0\n",
      "epoch: 8800, acc: 0.600, loss: 0.879, lr: 1.0\n",
      "epoch: 8900, acc: 0.597, loss: 0.871, lr: 1.0\n",
      "epoch: 9000, acc: 0.570, loss: 0.872, lr: 1.0\n",
      "epoch: 9100, acc: 0.630, loss: 0.880, lr: 1.0\n",
      "epoch: 9200, acc: 0.627, loss: 0.862, lr: 1.0\n",
      "epoch: 9300, acc: 0.613, loss: 0.848, lr: 1.0\n",
      "epoch: 9400, acc: 0.597, loss: 0.838, lr: 1.0\n",
      "epoch: 9500, acc: 0.607, loss: 0.844, lr: 1.0\n",
      "epoch: 9600, acc: 0.607, loss: 0.864, lr: 1.0\n",
      "epoch: 9700, acc: 0.607, loss: 0.881, lr: 1.0\n",
      "epoch: 9800, acc: 0.600, loss: 0.926, lr: 1.0\n",
      "epoch: 9900, acc: 0.610, loss: 0.915, lr: 1.0\n",
      "epoch: 10000, acc: 0.647, loss: 0.874, lr: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20f75af5d80>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Driver Code for SGD(Red Curve)\n",
    "# Create dataset\n",
    "from matplotlib import pyplot as plt\n",
    "loss_list2=[]\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# Create Dense layer with 2 input features and 64 output values\n",
    "dense1 = Layer_Dense(2, 64)\n",
    "\n",
    "# Create ReLU activation (to be used with Dense layer):\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "# Create second Dense layer with 64 input features (as we take output\n",
    "# of previous layer here) and 3 output values (output values)\n",
    "dense2 = Layer_Dense(64, 3)\n",
    "# Create Softmax classifier's combined loss and activation\n",
    "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = Optimizer_SGD()\n",
    "#optimizer = Optimizer_Adam(learning_rate=0.05, decay=5e-7)\n",
    "# Train in loop\n",
    "for epoch in range(10001):\n",
    "\n",
    "    # Perform a forward pass of our training data through this layer\n",
    "    dense1.forward(X)\n",
    "\n",
    "    # Perform a forward pass through activation function\n",
    "    # takes the output of first dense layer here\n",
    "    activation1.forward(dense1.output)\n",
    "\n",
    "    # Perform a forward pass through second Dense layer\n",
    "    # takes outputs of activation function of first layer as inputs\n",
    "    dense2.forward(activation1.output)\n",
    "\n",
    "    # Perform a forward pass through the activation/loss function\n",
    "    # takes the output of second dense layer here and returns loss\n",
    "    loss = loss_activation.forward(dense2.output, y)\n",
    "    loss_list2.append(loss)\n",
    "    # Calculate accuracy from output of activation2 and targets\n",
    "    # calculate values along first axis\n",
    "    predictions = np.argmax(loss_activation.output, axis=1)\n",
    "    if len(y.shape) == 2:\n",
    "        y = np.argmax(y, axis=1)\n",
    "    accuracy = np.mean(predictions==y)\n",
    "\n",
    "    if not epoch % 100:\n",
    "        \n",
    "        print(f'epoch: {epoch}, ' +\n",
    "              f'acc: {accuracy:.3f}, ' +\n",
    "              f'loss: {loss:.3f}, ' +\n",
    "              f'lr: {optimizer.current_learning_rate}')\n",
    "\n",
    "    # Backward pass\n",
    "    loss_activation.backward(loss_activation.output, y)\n",
    "    dense2.backward(loss_activation.dinputs)\n",
    "    activation1.backward(dense2.dinputs)\n",
    "    dense1.backward(activation1.dinputs)\n",
    "\n",
    "    # Update weights and biases\n",
    "    optimizer.pre_update_params()\n",
    "    optimizer.update_params(dense1)\n",
    "    optimizer.update_params(dense2)\n",
    "    optimizer.post_update_params()\n",
    "x1=range(epoch+1)\n",
    "plt.plot(x1,loss_list2,color='red')\n",
    "#plt.plot(x1,loss_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6186c377",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss_list1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18664\\1313729176.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_list1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_list2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'red'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_list3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'green'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_list4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loss_list1' is not defined"
     ]
    }
   ],
   "source": [
    "x1=range(epoch+1)\n",
    "plt.plot(x1,loss_list1)\n",
    "plt.plot(x1,loss_list2,color='red')\n",
    "plt.plot(x1,loss_list3,color='green')\n",
    "plt.plot(x1,loss_list4,color='m')\n",
    "plt.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
