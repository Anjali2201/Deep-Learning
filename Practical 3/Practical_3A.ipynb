{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network from Scratch\n",
    "# Practical 3A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the base layer\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "\n",
    "    def forward(self, input):\n",
    "        pass\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the Dense layer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class Layer_Dense(Layer):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.randn(output_size,input_size)\n",
    "        self.biases = np.random.randn(output_size,1)\n",
    "        \n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        return np.dot(self.weights, self.input ) + self.biases\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        weights_gradient = np.dot(output_gradient,self.input.T )\n",
    "        input_gradient = np.dot(self.weights.T, output_gradient)\n",
    "        self.weights -= learning_rate * weights_gradient\n",
    "        self.biases -=learning_rate * output_gradient\n",
    "        return input_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the activation layer\n",
    "\n",
    "class Activation(Layer):\n",
    "    def __init__(self, activation, activation_prime):\n",
    "        self.activation = activation\n",
    "        self.activation_prime = activation_prime\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        return self.activation(self.input)\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        return np.multiply(output_gradient, self.activation_prime(self.input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the activation functions\n",
    "\n",
    "# Tanh function\n",
    "class Tanh(Activation):\n",
    "    def __init__(self):\n",
    "        def tanh(x):\n",
    "            return np.tanh(x)\n",
    "        \n",
    "        def tanh_prime(x):\n",
    "            return 1 - np.tanh(x)**2\n",
    "        \n",
    "        super().__init__(tanh, tanh_prime)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the loss function\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean(np.power(y_true - y_pred, 2))\n",
    "\n",
    "# creating the loss function derivative\n",
    "\n",
    "def mse_prime(y_true, y_pred):\n",
    "    return 2 * (y_pred - y_true) / np.size(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Error 6.283071304761317\n",
      "Epoch 1000 Error 0.0017947628522256447\n",
      "Epoch 2000 Error 0.000867519791191938\n",
      "Epoch 3000 Error 0.0005696290607536705\n",
      "Epoch 4000 Error 0.0004233069108822448\n",
      "Epoch 5000 Error 0.00033649145498643873\n",
      "Epoch 6000 Error 0.0002790730963006292\n",
      "Epoch 7000 Error 0.00023830757634855676\n",
      "Epoch 8000 Error 0.00020788055460437644\n",
      "Epoch 9000 Error 0.0001843088258963989\n",
      "Final error:  4.138282798903351e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# creating the neural network\n",
    "\n",
    "X = np.reshape(([-1,-1],[-1,1],[1,-1],[1,1]),(4,2,1))\n",
    "Y = np.reshape(([-1],[1],[1],[-1]),(4,1,1))\n",
    "\n",
    "network = [\n",
    "    Layer_Dense(2, 3),\n",
    "    Tanh(),\n",
    "    Layer_Dense(3, 1),\n",
    "    Tanh()\n",
    "]\n",
    "\n",
    "epochs = 10000\n",
    "learning_rate = 0.1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    error = 0\n",
    "    for x, y in zip(X, Y):\n",
    "        # Forward pass\n",
    "        output = x\n",
    "        for layer in network:\n",
    "            output = layer.forward(output)\n",
    "\n",
    "        error += mse(y, output)\n",
    "        # Backward pass\n",
    "        output_gradient = mse_prime(y, output)\n",
    "        for layer in reversed(network):\n",
    "            output_gradient = layer.backward(output_gradient, learning_rate)\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(\"Epoch\",epoch,\"Error\",error)\n",
    "    \n",
    "error/= len (X)\n",
    "print(\"Final error: \",error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [[-1]\n",
      " [-1]] Output: [[-0.99199132]] Actual: [[-1]]\n",
      "_____________________________________________\n",
      "Input: [[-1]\n",
      " [ 1]] Output: [[0.99307019]] Actual: [[1]]\n",
      "_____________________________________________\n",
      "Input: [[ 1]\n",
      " [-1]] Output: [[0.99301929]] Actual: [[1]]\n",
      "_____________________________________________\n",
      "Input: [[1]\n",
      " [1]] Output: [[-0.99785497]] Actual: [[-1]]\n",
      "_____________________________________________\n"
     ]
    }
   ],
   "source": [
    "# testing the neural network\n",
    "\n",
    "input_arr = np.reshape(([-1,-1],[-1,1],[1,-1],[1,1]),(4,2,1))\n",
    "output_arr = np.reshape(([-1],[1],[1],[-1]),(4,1,1))\n",
    "\n",
    "for x, y in zip(input_arr, output_arr):\n",
    "    output = x\n",
    "    for layer in network:\n",
    "        output = layer.forward(output)\n",
    "\n",
    "    print(\"Input:\",x,\"Output:\",output,\"Actual:\",y)\n",
    "    print(\"_____________________________________________\")\n",
    "   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
